{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d39d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a58c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uh , hello doctor , good morning . How are you ?\n",
      " I am fine , thank you . How you are doing ?\n",
      " So , how is your headache now\n",
      " And which medicine you took last time\n",
      " It was , uh , .\n",
      " People who have hepatitis C are more on 500 mg\n",
      "\n",
      "\n",
      "Stopping.. as requested\n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import pyaudio\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import speech\n",
    "from six.moves import queue\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            stream_callback=self._fill_buffer)\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "            \n",
    "def listen_print_loop(responses):\n",
    "    \n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        print(transcript)\n",
    "            \n",
    "def main():\n",
    "    \n",
    "    language_code = \"en-US\" \n",
    "    google_speechtotext_apikey = service_account.Credentials.from_service_account_file('*********************.json')\n",
    "    client = speech.SpeechClient(credentials = google_speechtotext_apikey)\n",
    "    \n",
    "    diarization_config = speech.SpeakerDiarizationConfig(enable_speaker_diarization=True,\n",
    "                                                         min_speaker_count=2,\n",
    "                                                         max_speaker_count=3)\n",
    "    \n",
    "    config = speech.RecognitionConfig(encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                                      sample_rate_hertz=RATE,\n",
    "                                      language_code=language_code,\n",
    "                                      model = 'medical_conversation',\n",
    "                                      diarization_config=diarization_config)\n",
    "        \n",
    "    streaming_config = speech.StreamingRecognitionConfig(config=config, \n",
    "                                                         interim_results=False)\n",
    "    \n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (speech.StreamingRecognizeRequest(audio_content=content) for content in audio_generator)\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "        listen_print_loop(responses)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        print()\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print()\n",
    "        print(\"Stopping.. as requested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f027e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
